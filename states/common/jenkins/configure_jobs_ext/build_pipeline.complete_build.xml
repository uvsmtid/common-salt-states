<?xml version='1.0' encoding='UTF-8'?>
<project>
  <actions/>
  <description>{{ job_description }}</description>
  <keepDependencies>false</keepDependencies>
  <properties/>
  <scm class="hudson.scm.NullSCM"/>
  <assignedNode>{{ job_assigned_host }}</assignedNode>
  <canRoam>false</canRoam>
  <disabled>false</disabled>
  <blockBuildWhenDownstreamBuilding>false</blockBuildWhenDownstreamBuilding>
  <blockBuildWhenUpstreamBuilding>false</blockBuildWhenUpstreamBuilding>
  <triggers>

    {% if 'timer_spec' in job_config %}
    {% if job_config['timer_spec'] %}
    <hudson.triggers.TimerTrigger>
      <spec>{{ job_config['timer_spec'] }}</spec>
    </hudson.triggers.TimerTrigger>
    {% endif %}
    {% endif %}

  </triggers>
  <concurrentBuild>false</concurrentBuild>
  <builders>

    <!--
        Copy fingerprinted and archived artifact just for the sake
        of reliably linking this job to the initial one in the pipeline.
    -->
    <hudson.plugins.copyartifact.CopyArtifact plugin="copyartifact@1.35.2">
      <project>build_pipeline.init_dynamic_build_descriptor</project>
      <filter>dynamic_build_descriptor.yaml</filter>
      <target></target>
      <excludes></excludes>
      <selector class="hudson.plugins.copyartifact.TriggeredBuildSelector">
        <upstreamFilterStrategy>UseGlobalSetting</upstreamFilterStrategy>
      </selector>
      <doNotFingerprintArtifacts>false</doNotFingerprintArtifacts>
    </hudson.plugins.copyartifact.CopyArtifact>

    <hudson.tasks.Shell>
      <command>

        set -e
        set -u

        {% if 'skip_script_execution' in job_config and job_config['skip_script_execution'] %}
        exit 0
        {% endif %}

        #######################################################################
        # Locate dynamic build descriptor.

        {% from 'common/libs/host_config_queries.sls' import get_system_host_primary_user_posix_home with context %}

        # Get location of dynamic build descriptor (which is in pillar).
        {% set project_name = pillar['project_name'] %}
        {% if pillar['is_generic_profile'] %}
        {% set repo_config = pillar['system_features']['deploy_environment_sources']['source_repositories'][project_name + '-salt-states']['git'] %}
        {% else %}
        {% set repo_config = pillar['system_features']['deploy_environment_sources']['source_repositories'][project_name + '-salt-pillars']['git'] %}
        {% endif %}
        DYN_BUILD_DESC_PATH='{{ get_system_host_primary_user_posix_home(repo_config['source_system_host']) }}/{{ repo_config['origin_uri_ssh_path'] }}/pillars/profile/dynamic_build_descriptor.yaml'
        # Make sure file exists.
        ls -lrt ${DYN_BUILD_DESC_PATH}

        # We need to save this descriptor because we will switch back to
        # the initial branches.
        ORIG_DYN_BUILD_DESC_PATH="${DYN_BUILD_DESC_PATH}"
        DYN_BUILD_DESC_PATH="$(mktemp)"
        cp "${ORIG_DYN_BUILD_DESC_PATH}" "${DYN_BUILD_DESC_PATH}"

        #######################################################################
        # In-place Python script which returns data under
        # specified key in destination dict on stdout.

        # TODO: Put repeated in-place Python script into a file instead
        #       of copying and pasting them.

        KEY_GETTER_PYTHON_SCRIPT=$(mktemp)
        cat &lt;&lt;HEREDOC_MARKER &gt; ${KEY_GETTER_PYTHON_SCRIPT}
import os
import sys
import yaml

# Load data from dynamic descriptor.
with open(sys.argv[1], 'r') as yaml_file:
    loaded_data = yaml.load(yaml_file)

# If file was empty, its data is None, but we need a dict.
if loaded_data is None:
    loaded_data = {}

# Parse specification of the key provided on command line.
# The format should be 'parent-key:child-key:...:sub-key'
key_spec = sys.argv[2]
key_list = key_spec.split(':')
last_sub_key = key_list[-1]
curr_value = loaded_data
# Walk down to the last dictionary where 'last_sub_key' is.
for curr_key in key_list[:-1]:
    curr_value = curr_value[curr_key]
    assert(isinstance(curr_value, dict))

# Print content of the specified key to STDOUT.
print curr_value[last_sub_key]

HEREDOC_MARKER

        #######################################################################
        # Switch back to initial branches.

        # NOTE: We assume that repository is available
        #       locally on Jenkins slave.

        {% for repo_name in pillar['system_features']['deploy_environment_sources']['source_repositories'].keys() %}
        {% set repo_config = pillar['system_features']['deploy_environment_sources']['source_repositories'][repo_name]['git'] %}
        REPO_PATH="{{ get_system_host_primary_user_posix_home(repo_config['source_system_host']) }}/{{ repo_config['origin_uri_ssh_path'] }}"

        cd "${REPO_PATH}"
        CURRENT_BRANCH="$(git rev-parse --abbrev-ref HEAD)"
        # HEAD value means that repository is at detached head.
        test "${CURRENT_BRANCH}" != "HEAD"
        cd -

        INITIAL_BRANCH="$(python ${KEY_GETTER_PYTHON_SCRIPT} ${DYN_BUILD_DESC_PATH} "initial_branches:{{ repo_name }}")"
        BUILD_BRANCH_NAME="$(python ${KEY_GETTER_PYTHON_SCRIPT} ${DYN_BUILD_DESC_PATH} "build_branches:{{ repo_name }}")"
        test "${CURRENT_BRANCH}" == "${BUILD_BRANCH_NAME}"

        cd "${REPO_PATH}"
        git checkout "${INITIAL_BRANCH}"
        cd -

        {% endfor %}

        #######################################################################
        # TODO: Take special care to restore local files back to the conditions
        #       they were at the begining of the build pipeline
        #       (taking into account all local changes).
        #

        {% if False %} # DISABLED until it can run for parent first and for pillar last.

        # This step restores all local changes committed at the beginning.
        git checkout "${RESTORE_COMMIT_ID}"

        # This step resets HEAD to the commit before the beginning
        # while leaving all local files as they are at restore point.
        git reset "${INITIAL_BRANCH}"

        # This step simply checks out branch (moves away from detached HEAD).
        git checkout "${INITIAL_BRANCH}"

        {% endif %}

        #######################################################################
        # Remove all build branches.
        #
        # TODO: This better be done after promotion (which causes tagging).

        if [ "${REMOVE_BUILD_BRANCHES_AFTER_PIPELINE_COMPLETION}" == "true" ]
        then

        # Wait for a minute...
        sleep 60

        # Whether to fail the job or not.
        FAIL_JOB="false"

        {% for repo_name in pillar['system_features']['deploy_environment_sources']['source_repositories'].keys() %}
        {% set repo_config = pillar['system_features']['deploy_environment_sources']['source_repositories'][repo_name]['git'] %}
        REPO_PATH="{{ get_system_host_primary_user_posix_home(repo_config['source_system_host']) }}/{{ repo_config['origin_uri_ssh_path'] }}"

        cd "${REPO_PATH}"
        CURRENT_BRANCH="$(git rev-parse --abbrev-ref HEAD)"
        # HEAD value means that repository is at detached head.
        test "${CURRENT_BRANCH}" != "HEAD"
        cd -

        INITIAL_BRANCH="$(python ${KEY_GETTER_PYTHON_SCRIPT} ${DYN_BUILD_DESC_PATH} "initial_branches:{{ repo_name }}")"
        BUILD_BRANCH_NAME="$(python ${KEY_GETTER_PYTHON_SCRIPT} ${DYN_BUILD_DESC_PATH} "build_branches:{{ repo_name }}")"
        test "${CURRENT_BRANCH}" == "${INITIAL_BRANCH}"

        # Fail the job if there were any local changes at the start of pipeline.
        # This is because these changes might be something important,
        # and deleting the branch where they were stored deletes them as well.
        UNTRACKED_ITEMS="$(python ${KEY_GETTER_PYTHON_SCRIPT} ${DYN_BUILD_DESC_PATH} "untracked_items:{{ repo_name }}")"
        MODIFIED_ITEMS="$(python ${KEY_GETTER_PYTHON_SCRIPT} ${DYN_BUILD_DESC_PATH} "modified_items:{{ repo_name }}")"
        if false
        then
            echo NOOP
        elif [ "${UNTRACKED_ITEMS}" != "0" ]
        then
            FAIL_JOB="true"
            echo "ERROR: there were untracked files in {{ repo_name }}: ${UNTRACKED_ITEMS}"
        elif [ "${MODIFIED_ITEMS}" != "0" ]
        then
            FAIL_JOB="true"
            echo "ERROR: there were modified files in {{ repo_name }}: ${MODIFIED_ITEMS}"
        else
            cd "${REPO_PATH}"
            # Note that we ignore exit code (the command may fail and only logs may show why).
            set +e
            git branch -D "${BUILD_BRANCH_NAME}"
            set -e
            cd -
        fi

        {% endfor %}

        if [ "${FAIL_JOB}" == "true" ]
        then
            exit 1
        fi

        fi

        #######################################################################

      </command>
    </hudson.tasks.Shell>
  </builders>

  <publishers>

    {% if 'trigger_jobs' in job_config and job_config['trigger_jobs'] %}
    <hudson.plugins.parameterizedtrigger.BuildTrigger plugin="parameterized-trigger@2.26">
      <configs>
        <hudson.plugins.parameterizedtrigger.BuildTriggerConfig>
          <configs>
            <hudson.plugins.parameterizedtrigger.FileBuildParameters>
              <propertiesFile>{{ jenkins_dir_path }}/build.properties</propertiesFile>
              <failTriggerOnMissing>false</failTriggerOnMissing>
              <useMatrixChild>false</useMatrixChild>
              <onlyExactRuns>false</onlyExactRuns>
            </hudson.plugins.parameterizedtrigger.FileBuildParameters>
          </configs>
          <projects>{{ job_config['trigger_jobs']|join(',') }}</projects>
          <condition>SUCCESS</condition>
          <triggerWithNoParameters>true</triggerWithNoParameters>
        </hudson.plugins.parameterizedtrigger.BuildTriggerConfig>
      </configs>
    </hudson.plugins.parameterizedtrigger.BuildTrigger>
    {% endif %}

  </publishers>
  <buildWrappers/>
</project>
