<?xml version='1.0' encoding='UTF-8'?>
<project>
  <actions/>
  <description>{{ job_description }}</description>
  <keepDependencies>false</keepDependencies>
  <properties/>
  <scm class="hudson.scm.NullSCM"/>
  <assignedNode>{{ job_assigned_host }}</assignedNode>
  <canRoam>false</canRoam>
  <disabled>false</disabled>
  <blockBuildWhenDownstreamBuilding>false</blockBuildWhenDownstreamBuilding>
  <blockBuildWhenUpstreamBuilding>false</blockBuildWhenUpstreamBuilding>
  <triggers>

    {% if 'timer_spec' in job_config %}
    {% if job_config['timer_spec'] %}
    <hudson.triggers.TimerTrigger>
      <spec>{{ job_config['timer_spec'] }}</spec>
    </hudson.triggers.TimerTrigger>
    {% endif %}
    {% endif %}

  </triggers>
  <concurrentBuild>false</concurrentBuild>
  <builders>

    <!--
        Copy fingerprinted and archived artifact just for the sake
        of reliably linking this job to the initial one in the pipeline.
    -->
    <hudson.plugins.copyartifact.CopyArtifact plugin="copyartifact@1.35.2">
      <project>build_pipeline.init_dynamic_build_descriptor</project>
      <filter>dynamic_build_descriptor.yaml</filter>
      <target></target>
      <excludes></excludes>
      <selector class="hudson.plugins.copyartifact.TriggeredBuildSelector">
        <upstreamFilterStrategy>UseGlobalSetting</upstreamFilterStrategy>
      </selector>
      <doNotFingerprintArtifacts>false</doNotFingerprintArtifacts>
    </hudson.plugins.copyartifact.CopyArtifact>

    <hudson.tasks.Shell>
      <command>

        set -e
        set -u

        {% if 'skip_script_execution' in job_config and job_config['skip_script_execution'] %}
        exit 0
        {% endif %}

        #######################################################################
        # Locate dynamic build descriptor.

        {% from 'common/libs/host_config_queries.sls' import get_system_host_primary_user_posix_home with context %}

        # Get location of dynamic build descriptor (which is in pillar).
        {% set project_name = pillar['project_name'] %}
        {% if pillar['is_generic_profile'] %}
        {% set repo_config = pillar['system_features']['deploy_environment_sources']['source_repositories'][project_name + '-salt-states']['git'] %}
        {% else %}
        {% set repo_config = pillar['system_features']['deploy_environment_sources']['source_repositories'][project_name + '-salt-pillars']['git'] %}
        {% endif %}
        DYN_BUILD_DESC_PATH='{{ get_system_host_primary_user_posix_home(repo_config['source_system_host']) }}/{{ repo_config['origin_uri_ssh_path'] }}/pillars/profile/dynamic_build_descriptor.yaml'
        # Make sure file exists.
        ls -lrt ${DYN_BUILD_DESC_PATH}

        # In case of `init_build_branches` job, dynamic build descriptor
        # artifact copied from the `init_dynamic_build_descriptor` job
        # is the only way to get it (because generated
        # dynamic build descriptor hasn't been stored in the repository
        # directory yet). Repository directories stay intact until
        # this job since the start of the pipeline to produce true
        # recovery checkpoint (rather than already modified one with
        # generated files).

        # Therefore, at the moment the dynamic build descriptor
        # is simply a copy from `init_dynamic_build_descriptor` job
        # inside workspace.
        ORIG_DYN_BUILD_DESC_PATH="${DYN_BUILD_DESC_PATH}"
        DYN_BUILD_DESC_PATH="dynamic_build_descriptor.yaml"

        #######################################################################
        # In-place Python script which captures stdin data under
        # specified key in destination dict.

        # TODO: Put repeated in-place Python script into a file instead
        #       of copying and pasting them.

        KEY_SETTER_PYTHON_SCRIPT=$(mktemp)
        cat &lt;&lt;HEREDOC_MARKER &gt; ${KEY_SETTER_PYTHON_SCRIPT}
import os
import sys
import yaml

# Load data from dynamic descriptor.
with open(sys.argv[1], 'r') as yaml_file:
    loaded_data = yaml.load(yaml_file)

# If file was empty, its data is None, but we need a dict.
if loaded_data is None:
    loaded_data = {}

# Parse specification of the key provided on command line.
# The format should be 'parent-key:child-key:...:sub-key'
key_spec = sys.argv[2]
key_list = key_spec.split(':')
last_sub_key = key_list[-1]
curr_value = loaded_data
# Walk down to the last dictionary where 'last_sub_key' is.
for curr_key in key_list[:-1]:
    if curr_key not in curr_value:
        curr_value[curr_key] = {}
    curr_value = curr_value[curr_key]
    assert(isinstance(curr_value, dict))

# Assign content of STDIN to the specified key.
curr_value[last_sub_key] = sys.stdin.read().strip()

# Save dynamic build descriptor.
with open(sys.argv[1], 'w') as yaml_file:
    yaml.dump(
        loaded_data,
        yaml_file,
        default_flow_style = False,
        indent = 4,
    )

HEREDOC_MARKER

        #######################################################################
        # In-place Python script which returns data under
        # specified key in destination dict on stdout.

        # TODO: Put repeated in-place Python script into a file instead
        #       of copying and pasting them.

        KEY_GETTER_PYTHON_SCRIPT=$(mktemp)
        cat &lt;&lt;HEREDOC_MARKER &gt; ${KEY_GETTER_PYTHON_SCRIPT}
import os
import sys
import yaml

# Load data from dynamic descriptor.
with open(sys.argv[1], 'r') as yaml_file:
    loaded_data = yaml.load(yaml_file)

# If file was empty, its data is None, but we need a dict.
if loaded_data is None:
    loaded_data = {}

# Parse specification of the key provided on command line.
# The format should be 'parent-key:child-key:...:sub-key'
key_spec = sys.argv[2]
key_list = key_spec.split(':')
last_sub_key = key_list[-1]
curr_value = loaded_data
# Walk down to the last dictionary where 'last_sub_key' is.
for curr_key in key_list[:-1]:
    curr_value = curr_value[curr_key]
    assert(isinstance(curr_value, dict))

# Print content of the specified key to STDOUT.
print curr_value[last_sub_key]

HEREDOC_MARKER

        #######################################################################
        # Branch all repositories based on dynamic build descriptor.

        # NOTE: We assume that repository is available
        #       locally on Jenkins slave.

        {% for repo_name in pillar['system_features']['deploy_environment_sources']['source_repositories'].keys() %}
        {% set repo_config = pillar['system_features']['deploy_environment_sources']['source_repositories'][repo_name]['git'] %}
        REPO_PATH="{{ get_system_host_primary_user_posix_home(repo_config['source_system_host']) }}/{{ repo_config['origin_uri_ssh_path'] }}"

        cd "${REPO_PATH}"
        CURRENT_BRANCH="$(git rev-parse --abbrev-ref HEAD)"
        # HEAD value means that repository is at detached head.
        test "${CURRENT_BRANCH}" != "HEAD"
        cd -

        INITIAL_BRANCH="$(python ${KEY_GETTER_PYTHON_SCRIPT} ${DYN_BUILD_DESC_PATH} "initial_branches:{{ repo_name }}")"
        BUILD_BRANCH_NAME="$(python ${KEY_GETTER_PYTHON_SCRIPT} ${DYN_BUILD_DESC_PATH} "build_branches:{{ repo_name }}")"
        test "${CURRENT_BRANCH}" == "${INITIAL_BRANCH}"

        cd "${REPO_PATH}"
        git checkout -b "${BUILD_BRANCH_NAME}" "${INITIAL_BRANCH}"
        cd -

        {% endfor %}

        #######################################################################
        # Create restore point - initial commits of all local modifications.
        #
        # This restore point will be used to recover all local modifications
        # after switching back to initial branches even if build branches
        # are supposed to be deleted.
        #
        # Sequence:
        # - Save parent repo first
        #   (as commits in childs will not make original restore point).
        # - Save all other repos (children).

        # Save the 1st version of dynamic build descriptor.
        DYN_BUILD_DESC_V1_PATH="${DYN_BUILD_DESC_PATH}.v1"
        cp "${DYN_BUILD_DESC_PATH}" "${DYN_BUILD_DESC_V1_PATH}"

        {% if pillar['parent_repo_name'] %}
        # Parent repo is defined and it is the first.
        {% set repo_list = [ pillar['parent_repo_name'] ] + pillar['system_features']['deploy_environment_sources']['source_repositories'].keys() %}
        {% else %}
        # This profile does not define parent repo.
        {% set repo_list = pillar['system_features']['deploy_environment_sources']['source_repositories'].keys() %}
        {% endif %}

        {% for repo_name in repo_list %}
        {% set repo_config = pillar['system_features']['deploy_environment_sources']['source_repositories'][repo_name]['git'] %}
        REPO_PATH="{{ get_system_host_primary_user_posix_home(repo_config['source_system_host']) }}/{{ repo_config['origin_uri_ssh_path'] }}"

        cd "${REPO_PATH}"
        CURRENT_BRANCH="$(git rev-parse --abbrev-ref HEAD)"
        # HEAD value means that repository is at detached head.
        test "${CURRENT_BRANCH}" != "HEAD"
        cd -

        INITIAL_BRANCH="$(python ${KEY_GETTER_PYTHON_SCRIPT} ${DYN_BUILD_DESC_PATH} "initial_branches:{{ repo_name }}")"
        BUILD_BRANCH_NAME="$(python ${KEY_GETTER_PYTHON_SCRIPT} ${DYN_BUILD_DESC_PATH} "build_branches:{{ repo_name }}")"
        test "${CURRENT_BRANCH}" == "${BUILD_BRANCH_NAME}"

        cd "${REPO_PATH}"
        git add --all
        git status
        # Commit only if there are changes.
        # Ignore dirty content in submodules because there is no way to
        # commit them from top-level repo anyway (and all dirty content
        # will be committed by children).
        git diff-index --ignore-submodules=dirty --exit-code HEAD || git commit --author "${GIT_AUTHOR_EMAIL}" -m 'Auto-commit: restore point commit'
        RESTORE_POINT_COMMIT="$(git rev-parse --verify HEAD)"
        cd -

        echo "$RESTORE_POINT_COMMIT" | python ${KEY_SETTER_PYTHON_SCRIPT} ${DYN_BUILD_DESC_PATH} "restore_point_commit_ids:{{ repo_name }}"

        {% endfor %}

        # Save the 2nd version of dynamic build descriptor.
        DYN_BUILD_DESC_V2_PATH="${DYN_BUILD_DESC_PATH}.v2"
        cp "${DYN_BUILD_DESC_PATH}" "${DYN_BUILD_DESC_V2_PATH}"

        #######################################################################
        # Commit two version of dynamic build descriptor
        #
        # - Version 1 is pristine copy from `init_dynamic_build_descriptor`.
        # - Version 2 is updates with restore points.

        {% set project_name = pillar['project_name'] %}

        {% if pillar['is_generic_profile'] %}
        {% set repo_name = project_name + '-salt-states' %}
        {% else %}
        {% set repo_name = project_name + '-salt-pillars' %}
        {% endif %}

        # At the moment simply save it into repository.
        for DYN_BUILD_DESC_PATH in "${DYN_BUILD_DESC_V1_PATH}" "${DYN_BUILD_DESC_V2_PATH}"
        do

        cp "${DYN_BUILD_DESC_PATH}" "${ORIG_DYN_BUILD_DESC_PATH}"

        {% set repo_config = pillar['system_features']['deploy_environment_sources']['source_repositories'][repo_name]['git'] %}
        REPO_PATH="{{ get_system_host_primary_user_posix_home(repo_config['source_system_host']) }}/{{ repo_config['origin_uri_ssh_path'] }}"

        cd "${REPO_PATH}"
        CURRENT_BRANCH="$(git rev-parse --abbrev-ref HEAD)"
        # HEAD value means that repository is at detached head.
        test "${CURRENT_BRANCH}" != "HEAD"
        cd -

        INITIAL_BRANCH="$(python ${KEY_GETTER_PYTHON_SCRIPT} ${DYN_BUILD_DESC_PATH} "initial_branches:{{ repo_name }}")"
        BUILD_BRANCH_NAME="$(python ${KEY_GETTER_PYTHON_SCRIPT} ${DYN_BUILD_DESC_PATH} "build_branches:{{ repo_name }}")"
        test "${CURRENT_BRANCH}" == "${BUILD_BRANCH_NAME}"

        cd "${REPO_PATH}"
        git add --all
        git status
        # Note that we don't check whether there are changes to commit.
        # There must be changes - each version of
        # dynamic build descriptor should be different.
        git commit --author "${GIT_AUTHOR_EMAIL}" -m 'Auto-commit: dynamic build descriptor'
        cd -

        done

        #######################################################################

      </command>
    </hudson.tasks.Shell>
  </builders>

  <publishers>

    {% if 'trigger_jobs' in job_config and job_config['trigger_jobs'] %}
    <hudson.plugins.parameterizedtrigger.BuildTrigger plugin="parameterized-trigger@2.26">
      <configs>
        <hudson.plugins.parameterizedtrigger.BuildTriggerConfig>
          <configs>
            <hudson.plugins.parameterizedtrigger.FileBuildParameters>
              <propertiesFile>{{ jenkins_dir_path }}/build.properties</propertiesFile>
              <failTriggerOnMissing>false</failTriggerOnMissing>
              <useMatrixChild>false</useMatrixChild>
              <onlyExactRuns>false</onlyExactRuns>
            </hudson.plugins.parameterizedtrigger.FileBuildParameters>
          </configs>
          <projects>{{ job_config['trigger_jobs']|join(',') }}</projects>
          <condition>SUCCESS</condition>
          <triggerWithNoParameters>true</triggerWithNoParameters>
        </hudson.plugins.parameterizedtrigger.BuildTriggerConfig>
      </configs>
    </hudson.plugins.parameterizedtrigger.BuildTrigger>
    {% endif %}

  </publishers>
  <buildWrappers/>
</project>
